# Baseball Win Crawler 개발 계획

## 프로젝트 현황 (2025-01-13)

### 완료된 작업
- ✅ 프로젝트 기본 구조 설정
- ✅ 여러 크롤러 구현 (Selenium, API, Simple)
- ✅ 데이터 저장/조회 기능
- ✅ 스케줄러 및 로깅 시스템
- ✅ 가상환경 설정 스크립트 (setup.sh)

### 현재 문제점
- ❌ 실제 웹 크롤링이 작동하지 않음 (더미 데이터만 사용)
- ❌ 소스 파일의 한글 인코딩 문제
- ❌ 여러 크롤러가 중복되어 있음

## 개발 로드맵

### 📌 1단계: 실제 작동하는 데이터 소스 찾기 ✅ 완료
**목표**: 안정적으로 KBO 경기 데이터를 가져올 수 있는 소스 확보

#### 작업 내용
- [x] KBO 공식 사이트 API 재검증
  - POST /ws/Schedule.asmx/GetScheduleList 엔드포인트 테스트 → 500 에러
  - 서버 측 문제로 사용 불가
- [x] 네이버 스포츠 API 분석
  - 모바일 API 엔드포인트 찾기 → 404 에러
  - 웹 버전 크롤링 가능성 검토 → JavaScript 렌더링 필요
- [x] 대체 데이터 소스 탐색
  - StatIz 사이트 구조 분석 → 일정 페이지 대신 통계 페이지 반환
  - 다른 사이트들도 모두 JavaScript 렌더링 필요
- [x] 각 소스별 안정성 테스트
  - 모든 소스가 클라이언트 사이드 렌더링 사용
  - 단순 requests로는 데이터 수집 불가능

#### 결론
- 브라우저 자동화 도구(Selenium/Playwright) 필수
- Playwright가 가장 현대적이고 안정적인 선택

### 📌 1-1단계: Playwright 기반 크롤러 구현 ✅ 완료
**목표**: JavaScript 렌더링이 필요한 사이트에서 데이터 수집

#### 작업 내용
- [x] Playwright 설치 및 설정
- [x] 네이버 스포츠 크롤러 구현
- [x] KBO 공식 사이트 크롤러 구현
- [x] 안정성 및 성능 테스트

#### 결과
- Playwright 크롤러 구현 완료
- 현재 실제 데이터 수집은 실패 (사이트 구조 변경)
- 더미 데이터로 시스템 작동 확인

### 📌 2단계: 인코딩 문제 해결
**목표**: 모든 소스 파일의 한글이 정상적으로 표시되도록 수정

#### 작업 내용
- [ ] 파일별 인코딩 상태 점검
- [ ] UTF-8로 일괄 변환
- [ ] 파일 저장 시 인코딩 명시
- [ ] IDE 설정 확인

### 📌 3단계: 크롤러 통합 및 정리
**목표**: 가장 안정적인 크롤러를 메인으로 선정하고 코드 정리

#### 작업 내용
- [ ] 각 크롤러의 장단점 분석
- [ ] 메인 크롤러 선정
- [ ] 백업 크롤러 로직 구현
- [ ] 불필요한 코드 제거

### 📌 4단계: 실제 데이터 테스트
**목표**: 더미 데이터 없이 실제 경기 데이터로 전체 시스템 검증

#### 작업 내용
- [ ] 어제 경기 데이터 크롤링
- [ ] 데이터 파싱 정확성 검증
- [ ] 저장 파일 형식 확인
- [ ] 통계 기능 테스트

### 📌 5단계: 안정성 강화
**목표**: 프로덕션 환경에서 안정적으로 동작하도록 개선

#### 작업 내용
- [ ] 재시도 로직 구현 (exponential backoff)
- [ ] 상세한 에러 핸들링
- [ ] 데이터 검증 로직 추가
- [ ] 모니터링 기능 구현

## 기술 스택
- Python 3.x
- BeautifulSoup4 (HTML 파싱)
- Selenium (동적 페이지)
- Requests (HTTP 요청)
- Schedule (작업 스케줄링)

## 현재 상태 요약

### 완료된 작업
1. ✅ 가상환경 설정 스크립트 (setup.sh)
2. ✅ 데이터 소스 분석 완료
   - KBO API: 500 에러
   - 네이버 API: 404 에러
   - 모든 사이트 JavaScript 렌더링 필요
3. ✅ Playwright 크롤러 구현
   - 더미 데이터로 작동 확인
   - JSON/CSV 파일 저장 기능 정상

### 남은 작업
1. 인코딩 문제 해결
2. 크롤러 통합 및 정리
3. 실제 데이터 크롤링 (사이트 구조 분석 필요)
4. 에러 처리 강화

## 사용 방법

### 환경 설정
```bash
# 가상환경 설정 (기본 이름: venv)
./setup.sh

# 커스텀 이름으로 가상환경 설정
./setup.sh myenv

# 가상환경 활성화
source venv/bin/activate  # macOS/Linux
source venv/Scripts/activate  # Windows

# Playwright 브라우저 설치 (최초 1회)
playwright install chromium
```

### 실행 명령어
```bash
# 어제 경기 크롤링
python main.py --once

# 특정 날짜 크롤링
python main.py --date 20241015

# 스케줄러 실행 (매일 10:00)
python main.py

# 팀별 통계 조회
python main.py --team KIA
```

## 참고 사항
- 크롤링 시 과도한 요청은 IP 차단의 원인이 될 수 있음
- robots.txt 및 사이트 이용약관 준수 필요
- 데이터는 개인 사용 목적으로만 활용