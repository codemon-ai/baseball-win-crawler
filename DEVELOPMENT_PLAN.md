# Baseball Win Crawler 개발 계획

## 프로젝트 현황 (2025-01-13)

### 완료된 작업
- ✅ 프로젝트 기본 구조 설정
- ✅ 여러 크롤러 구현 (Selenium, API, Simple)
- ✅ 데이터 저장/조회 기능
- ✅ 스케줄러 및 로깅 시스템
- ✅ 가상환경 설정 스크립트 (setup.sh)

### 현재 문제점
- ❌ 실제 웹 크롤링이 작동하지 않음 (더미 데이터만 사용)
- ❌ 소스 파일의 한글 인코딩 문제
- ❌ 여러 크롤러가 중복되어 있음

## 개발 로드맵

### 📌 1단계: 실제 작동하는 데이터 소스 찾기 ✅ 완료
**목표**: 안정적으로 KBO 경기 데이터를 가져올 수 있는 소스 확보

#### 작업 내용
- [x] KBO 공식 사이트 API 재검증
  - POST /ws/Schedule.asmx/GetScheduleList 엔드포인트 테스트 → 500 에러
  - 서버 측 문제로 사용 불가
- [x] 네이버 스포츠 API 분석
  - 모바일 API 엔드포인트 찾기 → 404 에러
  - 웹 버전 크롤링 가능성 검토 → JavaScript 렌더링 필요
- [x] 대체 데이터 소스 탐색
  - StatIz 사이트 구조 분석 → 일정 페이지 대신 통계 페이지 반환
  - 다른 사이트들도 모두 JavaScript 렌더링 필요
- [x] 각 소스별 안정성 테스트
  - 모든 소스가 클라이언트 사이드 렌더링 사용
  - 단순 requests로는 데이터 수집 불가능

#### 결론
- 브라우저 자동화 도구(Selenium/Playwright) 필수
- Playwright가 가장 현대적이고 안정적인 선택

### 📌 1-1단계: Playwright 기반 크롤러 구현 ✅ 완료
**목표**: JavaScript 렌더링이 필요한 사이트에서 데이터 수집

#### 작업 내용
- [x] Playwright 설치 및 설정
- [x] 네이버 스포츠 크롤러 구현
- [x] KBO 공식 사이트 크롤러 구현
- [x] 안정성 및 성능 테스트

#### 결과
- Playwright 크롤러 구현 완료
- 현재 실제 데이터 수집은 실패 (사이트 구조 변경)
- 더미 데이터로 시스템 작동 확인

### 📌 2단계: 인코딩 문제 해결
**목표**: 모든 소스 파일의 한글이 정상적으로 표시되도록 수정

#### 작업 내용
- [ ] 파일별 인코딩 상태 점검
- [ ] UTF-8로 일괄 변환
- [ ] 파일 저장 시 인코딩 명시
- [ ] IDE 설정 확인

### 📌 3단계: 크롤러 통합 및 정리
**목표**: 가장 안정적인 크롤러를 메인으로 선정하고 코드 정리

#### 작업 내용
- [ ] 각 크롤러의 장단점 분석
- [ ] 메인 크롤러 선정
- [ ] 백업 크롤러 로직 구현
- [ ] 불필요한 코드 제거

### 📌 4단계: 실제 데이터 테스트
**목표**: 더미 데이터 없이 실제 경기 데이터로 전체 시스템 검증

#### 작업 내용
- [ ] 어제 경기 데이터 크롤링
- [ ] 데이터 파싱 정확성 검증
- [ ] 저장 파일 형식 확인
- [ ] 통계 기능 테스트

### 📌 5단계: 안정성 강화
**목표**: 프로덕션 환경에서 안정적으로 동작하도록 개선

#### 작업 내용
- [ ] 재시도 로직 구현 (exponential backoff)
- [ ] 상세한 에러 핸들링
- [ ] 데이터 검증 로직 추가
- [ ] 모니터링 기능 구현

## 기술 스택
- Python 3.x
- BeautifulSoup4 (HTML 파싱)
- Selenium (동적 페이지)
- Requests (HTTP 요청)
- Schedule (작업 스케줄링)

## 현재 상태 요약 (2025-01-13 업데이트)

### 완료된 작업
1. ✅ 가상환경 설정 스크립트 (setup.sh)
2. ✅ 데이터 소스 분석 완료
   - KBO API: 500 에러
   - 네이버 API: 404 에러
   - 모든 사이트 JavaScript 렌더링 필요
3. ✅ Playwright 크롤러 구현
   - 더미 데이터로 작동 확인
   - JSON/CSV 파일 저장 기능 정상
4. ✅ **KBO 공식 사이트 크롤러 구현 성공**
   - 실제 경기 데이터 크롤링 성공
   - Playwright 기반으로 JavaScript 렌더링 처리
5. ✅ **통합 크롤러 구현**
   - KBO 공식 사이트를 메인 데이터 소스로 사용
   - unified_crawler.py로 모든 크롤러 통합
6. ✅ **테스트 파일 정리 (2025-01-13)**
   - 모든 test_*.py 파일을 tests/ 디렉토리로 이동
   - import 경로 정리 (sys.path 설정 확인)
   - .gitignore에 test_baseball/ 가상환경 추가

### 다음 단계
1. **날짜별 정확한 데이터 크롤링 개선**
   - 현재 날짜 선택이 제대로 작동하지 않음
   - 특정 날짜의 경기만 정확히 가져오도록 개선 필요
   
2. **중복 제거 로직 강화**
   - 동일한 경기가 여러 번 나타나는 문제 해결
   - 정규시즌/포스트시즌 구분
   
3. **테스트 코드 작성**
   - pytest 기반 단위 테스트
   - 크롤러 통합 테스트
   
4. **에러 처리 및 재시도 로직**
   - 네트워크 오류 시 재시도
   - 크롤링 실패 시 백업 소스 사용
   
5. **성능 최적화**
   - 캐싱 구현
   - 동시성 처리
   
6. **CI/CD 파이프라인 구축**
   - GitHub Actions 설정
   - 자동 테스트 및 배포
   
7. **모니터링 및 알림**
   - 크롤링 실패 시 알림
   - 일일 리포트 생성

## 사용 방법

### 환경 설정
```bash
# 가상환경 설정 (기본 이름: venv)
./setup.sh

# 커스텀 이름으로 가상환경 설정
./setup.sh myenv

# 가상환경 활성화
source venv/bin/activate  # macOS/Linux
source venv/Scripts/activate  # Windows

# Playwright 브라우저 설치 (최초 1회)
playwright install chromium
```

### 실행 명령어
```bash
# 어제 경기 크롤링
python main.py --once

# 특정 날짜 크롤링
python main.py --date 20241015

# 스케줄러 실행 (매일 10:00)
python main.py

# 팀별 통계 조회
python main.py --team KIA
```

## 참고 사항
- 크롤링 시 과도한 요청은 IP 차단의 원인이 될 수 있음
- robots.txt 및 사이트 이용약관 준수 필요
- 데이터는 개인 사용 목적으로만 활용